{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjAdM22O7xk2",
        "outputId": "aa7a3b0a-eb8b-4d97-9237-7f769ad82c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# iniciando a sessão com o pyspark\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"DesmatamentoBR\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importando os dados do kaggle\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mbogernetto/brazilian-amazon-rainforest-degradation\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ0-uYi28JVl",
        "outputId": "0ef2f21f-5f2b-4def-eacc-55684db47583"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mbogernetto/brazilian-amazon-rainforest-degradation?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 45.9k/45.9k [00:00<00:00, 15.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/mbogernetto/brazilian-amazon-rainforest-degradation/versions/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o tipo do arquivo\n",
        "import os\n",
        "\n",
        "path = '/kaggle/input/brazilian-amazon-rainforest-degradation'\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "mfKJy2HM8aEn",
        "outputId": "6e2b4801-35d3-43fe-fdc1-051e6cde7204"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/brazilian-amazon-rainforest-degradation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-3953059587.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/input/brazilian-amazon-rainforest-degradation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/brazilian-amazon-rainforest-degradation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura dos dataframes utilizados\n",
        "# Dados de queimadas (focos de incêndio por estado/mês)\n",
        "fires_df = spark.read.csv(\n",
        "    path + '/inpe_brazilian_amazon_fires_1999_2019.csv',\n",
        "    header=True,\n",
        "    inferSchema=True\n",
        ")\n",
        "fires_df.show(5)\n",
        "\n",
        "# Eventos climáticos (El Niño / La Niña)\n",
        "climate_events_df = spark.read.csv(\n",
        "    path + '/el_nino_la_nina_1999_2019.csv',\n",
        "    header=True,\n",
        "    inferSchema=True\n",
        ")\n",
        "climate_events_df.show(5)\n",
        "\n",
        "# Resumo anual por estado da Amazônia Legal\n",
        "annual_summary_df = spark.read.csv(\n",
        "    path + '/def_area_2004_2019.csv',\n",
        "    header=True,\n",
        "    inferSchema=True\n",
        ")\n",
        "annual_summary_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVo-70nVQJvt",
        "outputId": "d6a55d80-8bb0-4d35-a8b4-420c574c40d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----------+-------------------+-------------------+---------+\n",
            "|year|month|      state|           latitude|          longitude|firespots|\n",
            "+----+-----+-----------+-------------------+-------------------+---------+\n",
            "|1999|    1|   AMAZONAS| -2.371113333333333| -59.89993333333334|        3|\n",
            "|1999|    1|   MARANHAO| -2.257394722222222|-45.487830555555554|       36|\n",
            "|1999|    1|MATO GROSSO|-12.660633333333333|-55.057988888888886|       18|\n",
            "|1999|    1|       PARA| -2.474820459770115| -48.54696666666667|       87|\n",
            "|1999|    1|   RONDONIA|           -12.8617|           -60.5131|        1|\n",
            "+----+-----+-----------+-------------------+-------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+--------+----------+--------+\n",
            "|start year|end year|phenomenon|severity|\n",
            "+----------+--------+----------+--------+\n",
            "|      2004|    2005|   El Nino|    Weak|\n",
            "|      2006|    2007|   El Nino|    Weak|\n",
            "|      2014|    2015|   El Nino|    Weak|\n",
            "|      2018|    2019|   El Nino|    Weak|\n",
            "|      2002|    2003|   El Nino|Moderate|\n",
            "+----------+--------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------+---+----+---+----+-----+----+----+---+---+---------+\n",
            "|Ano/Estados| AC|  AM| AP|  MA|   MT|  PA|  RO| RR| TO|AMZ LEGAL|\n",
            "+-----------+---+----+---+----+-----+----+----+---+---+---------+\n",
            "|       2004|728|1232| 46| 755|11814|8870|3858|311|158|    27772|\n",
            "|       2005|592| 775| 33| 922| 7145|5899|3244|133|271|    19014|\n",
            "|       2006|398| 788| 30| 674| 4333|5659|2049|231|124|    14286|\n",
            "|       2007|184| 610| 39| 631| 2678|5526|1611|309| 63|    11651|\n",
            "|       2008|254| 604|100|1271| 3258|5607|1136|574|107|    12911|\n",
            "+-----------+---+----+---+----+-----+----+----+---+---+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padronizar e limpeza do dados\n",
        "fires = fires_df\n",
        "climate = climate_events_df\n",
        "summary = annual_summary_df\n",
        "\n",
        "fires = fires.dropDuplicates()\n",
        "climate = climate.dropDuplicates()\n",
        "summary = summary.dropDuplicates()"
      ],
      "metadata": {
        "id": "XBvnli40Sv0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando dados nulos\n",
        "from pyspark.sql import functions as F\n",
        "for df, name in zip([fires, climate, summary], ['fires', 'climate', 'summary']):\n",
        "    print(f\"{name}:\")\n",
        "    df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqGqt69xTDwg",
        "outputId": "be76d4c9-0b5d-4edf-9a60-ca705421d5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fires:\n",
            "+----+-----+-----+--------+---------+---------+\n",
            "|year|month|state|latitude|longitude|firespots|\n",
            "+----+-----+-----+--------+---------+---------+\n",
            "|   0|    0|    0|       0|        0|        0|\n",
            "+----+-----+-----+--------+---------+---------+\n",
            "\n",
            "climate:\n",
            "+----------+--------+----------+--------+\n",
            "|start year|end year|phenomenon|severity|\n",
            "+----------+--------+----------+--------+\n",
            "|         0|       0|         0|       0|\n",
            "+----------+--------+----------+--------+\n",
            "\n",
            "summary:\n",
            "+-----------+---+---+---+---+---+---+---+---+---+---------+\n",
            "|Ano/Estados| AC| AM| AP| MA| MT| PA| RO| RR| TO|AMZ LEGAL|\n",
            "+-----------+---+---+---+---+---+---+---+---+---+---------+\n",
            "|          0|  0|  0|  0|  0|  0|  0|  0|  0|  0|        0|\n",
            "+-----------+---+---+---+---+---+---+---+---+---+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Expandir anos dos fenômenos climáticos\n",
        "climate = climate.withColumn(\n",
        "    \"year\", F.explode(F.sequence(F.col(\"start year\"), F.col(\"end year\")))\n",
        ").drop(\"start year\", \"end year\")\n",
        "\n",
        "climate.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41iJXWgdUJQA",
        "outputId": "aa216a23-0e3c-4cc5-ae6d-90586b023a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+----+\n",
            "|phenomenon|severity|year|\n",
            "+----------+--------+----+\n",
            "|   La Nina|    Weak|2008|\n",
            "|   La Nina|    Weak|2009|\n",
            "|   La Nina|  Strong|1999|\n",
            "|   La Nina|  Strong|2000|\n",
            "|   La Nina|    Weak|2005|\n",
            "+----------+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padronizar tipos e colunas\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "summary = summary.withColumnRenamed(\"Ano/Estados\", \"year\")\n",
        "\n",
        "summary_long = summary.select(\n",
        "    \"year\",\n",
        "    *[F.struct(F.lit(col).alias(\"state\"), F.col(col).alias(\"total_fires\")).alias(col) for col in summary.columns if col not in [\"year\", \"AMZ LEGAL\"]]\n",
        ").select(\"year\", *summary.columns[1:-1])\n",
        "\n",
        "# Transformar wide para long (explode)\n",
        "summary_long = summary.selectExpr(\"year\", \"stack(9, 'AC', AC, 'AM', AM, 'AP', AP, 'MA', MA, 'MT', MT, 'PA', PA, 'RO', RO, 'RR', RR, 'TO', TO) as (state, summary_fires)\")\n",
        "\n",
        "# padronizando o nome dos estados para ficar igual a tabela fires\n",
        "summary_long = summary_long.withColumn(\n",
        "    \"state\",\n",
        "    when(col(\"state\") == \"AC\", \"ACRE\")\n",
        "    .when(col(\"state\") == \"AM\", \"AMAZONAS\")\n",
        "    .when(col(\"state\") == \"AP\", \"AMAPA\")\n",
        "    .when(col(\"state\") == \"MA\", \"MARANHAO\")\n",
        "    .when(col(\"state\") == \"MT\", \"MATO GROSSO\")\n",
        "    .when(col(\"state\") == \"PA\", \"PARA\")\n",
        "    .when(col(\"state\") == \"RO\", \"RONDONIA\")\n",
        "    .when(col(\"state\") == \"RR\", \"RORAIMA\")\n",
        "    .when(col(\"state\") == \"TO\", \"TOCANTINS\")\n",
        "    .otherwise(col(\"state\"))\n",
        ")\n",
        "\n",
        "summary_long.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4DYaVFlTy5A",
        "outputId": "f8ab791f-dfa1-4c3b-f823-2e4ebcfe63fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+-------------+\n",
            "|year|      state|summary_fires|\n",
            "+----+-----------+-------------+\n",
            "|2009|       ACRE|          167|\n",
            "|2009|   AMAZONAS|          405|\n",
            "|2009|      AMAPA|           70|\n",
            "|2009|   MARANHAO|          828|\n",
            "|2009|MATO GROSSO|         1049|\n",
            "+----+-----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregar focos por ano/estado\n",
        "fires_agg = fires.groupBy(\"year\", \"state\").agg(F.sum(\"firespots\").alias(\"total_fires\"))\n",
        "\n",
        "fires_agg.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLQ2xabbUnVA",
        "outputId": "ba043c70-16a5-47b1-d483-312f655767c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+-----------+\n",
            "|year|      state|total_fires|\n",
            "+----+-----------+-----------+\n",
            "|2014|MATO GROSSO|      15677|\n",
            "|2004|MATO GROSSO|      70422|\n",
            "|2002|   AMAZONAS|      10203|\n",
            "|2009|      AMAPA|       2456|\n",
            "|2018|  TOCANTINS|        281|\n",
            "+----+-----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fazer a junção\n",
        "fires_climate = fires_agg.join(climate, on=\"year\", how=\"left\")\n",
        "fires_final = fires_climate.join(summary_long, on=[\"year\", \"state\"], how=\"left\")\n",
        "\n",
        "fires_final.show(25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8aVmAyOUuTT",
        "outputId": "d9186ae2-40db-49a6-e07d-8d21779c23c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+-----------+----------+-----------+-------------+\n",
            "|year|      state|total_fires|phenomenon|   severity|summary_fires|\n",
            "+----+-----------+-----------+----------+-----------+-------------+\n",
            "|2014|MATO GROSSO|      15677|   El Nino|       Weak|         1075|\n",
            "|2004|MATO GROSSO|      70422|   El Nino|       Weak|        11814|\n",
            "|2002|   AMAZONAS|      10203|   El Nino|   Moderate|         NULL|\n",
            "|2009|      AMAPA|       2456|   El Nino|   Moderate|           70|\n",
            "|2009|      AMAPA|       2456|   La Nina|       Weak|           70|\n",
            "|2018|  TOCANTINS|        281|   La Nina|       Weak|           25|\n",
            "|2018|  TOCANTINS|        281|   El Nino|       Weak|           25|\n",
            "|2016|       ACRE|       7684|   La Nina|       Weak|          372|\n",
            "|2016|       ACRE|       7684|   El Nino|Very Strong|          372|\n",
            "|2012|       ACRE|       4720|   La Nina|   Moderate|          305|\n",
            "|2001|   AMAZONAS|       1297|   La Nina|       Weak|         NULL|\n",
            "|2018|   AMAZONAS|      11446|   La Nina|       Weak|         1045|\n",
            "|2018|   AMAZONAS|      11446|   El Nino|       Weak|         1045|\n",
            "|2010|      AMAPA|       1000|   El Nino|   Moderate|           53|\n",
            "|2010|      AMAPA|       1000|   La Nina|     Strong|           53|\n",
            "|2005|       ACRE|      15993|   El Nino|       Weak|          592|\n",
            "|2005|       ACRE|      15993|   La Nina|       Weak|          592|\n",
            "|2016|  TOCANTINS|        489|   La Nina|       Weak|           58|\n",
            "|2016|  TOCANTINS|        489|   El Nino|Very Strong|           58|\n",
            "|2010|       ACRE|       8661|   El Nino|   Moderate|          259|\n",
            "|2010|       ACRE|       8661|   La Nina|     Strong|          259|\n",
            "|2019|   AMAZONAS|      12665|   El Nino|       Weak|         1421|\n",
            "|2012|   MARANHAO|       6919|   La Nina|   Moderate|          269|\n",
            "|2000|MATO GROSSO|      17242|   La Nina|       Weak|         NULL|\n",
            "|2000|MATO GROSSO|      17242|   La Nina|     Strong|         NULL|\n",
            "+----+-----------+-----------+----------+-----------+-------------+\n",
            "only showing top 25 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criar colunas derivadas\n",
        "# intensidade de fogo\n",
        "from pyspark.sql.functions import col, when, avg\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Calcular os quartis\n",
        "quantiles = fires_final.approxQuantile(\"total_fires\", [0.25, 0.75], 0.01)\n",
        "q1 = quantiles[0]\n",
        "q3 = quantiles[1]\n",
        "\n",
        "# Criar coluna fire_level com base nos quartis\n",
        "fires_final = fires_final.withColumn(\n",
        "    \"fire_level\",\n",
        "    when(col(\"total_fires\") <= q1, \"Low\")\n",
        "    .when((col(\"total_fires\") > q1) & (col(\"total_fires\") <= q3), \"Medium\")\n",
        "    .otherwise(\"High\")\n",
        ")\n",
        "\n",
        "# Média de focos por estado (sem considerar o ano atual)\n",
        "window_spec = Window.partitionBy(\"state\")\n",
        "\n",
        "# Cria a coluna fire_anomaly que mostra se houve menos ou mais queimadas em relação com a média\n",
        "fires_final = fires_final.withColumn(\n",
        "    \"avg_state_fires\", avg(\"total_fires\").over(window_spec)\n",
        ").withColumn(\n",
        "    \"fire_anomaly\", col(\"total_fires\") - col(\"avg_state_fires\")\n",
        ")\n",
        "\n",
        "fires_final.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYwFvYpFZscU",
        "outputId": "81ac2daf-8e31-4469-d061-3828db8aac20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-----------+----------+-----------+-------------+----------+-----------------+------------------+\n",
            "|year|state|total_fires|phenomenon|   severity|summary_fires|fire_level|  avg_state_fires|      fire_anomaly|\n",
            "+----+-----+-----------+----------+-----------+-------------+----------+-----------------+------------------+\n",
            "|2016| ACRE|       7684|   La Nina|       Weak|          372|    Medium|6214.757575757576| 1469.242424242424|\n",
            "|2016| ACRE|       7684|   El Nino|Very Strong|          372|    Medium|6214.757575757576| 1469.242424242424|\n",
            "|2012| ACRE|       4720|   La Nina|   Moderate|          305|    Medium|6214.757575757576|-1494.757575757576|\n",
            "|2005| ACRE|      15993|   El Nino|       Weak|          592|      High|6214.757575757576| 9778.242424242424|\n",
            "|2005| ACRE|      15993|   La Nina|       Weak|          592|      High|6214.757575757576| 9778.242424242424|\n",
            "+----+-----+-----------+----------+-----------+-------------+----------+-----------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregando para haver apenas um linha por ano e estados\n",
        "from pyspark.sql.functions import avg, sum\n",
        "\n",
        "fires_agg_df = fires_final.groupBy(\"year\", \"state\").agg(\n",
        "    avg(\"total_fires\").alias(\"avg_total_fires\"),\n",
        "    avg(\"summary_fires\").alias(\"avg_summary_fires\"),\n",
        "    avg(\"fire_anomaly\").alias(\"avg_fire_anomaly\")\n",
        ")\n",
        "fires_agg_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c04EZ9_fLyNy",
        "outputId": "8a66be0e-d630-4ba0-be0c-bbb4d090f6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+---------------+-----------------+------------------+\n",
            "|year|state|avg_total_fires|avg_summary_fires|  avg_fire_anomaly|\n",
            "+----+-----+---------------+-----------------+------------------+\n",
            "|2016| ACRE|         7684.0|            372.0| 1469.242424242424|\n",
            "|2012| ACRE|         4720.0|            305.0|-1494.757575757576|\n",
            "|2005| ACRE|        15993.0|            592.0| 9778.242424242424|\n",
            "|2010| ACRE|         8661.0|            259.0| 2446.242424242424|\n",
            "|2001| ACRE|          829.0|             NULL|-5385.757575757576|\n",
            "|2018| ACRE|         6626.0|            444.0|  411.242424242424|\n",
            "|2014| ACRE|         4398.0|            309.0|-1816.757575757576|\n",
            "|2007| ACRE|         8549.0|            184.0| 2334.242424242424|\n",
            "|2004| ACRE|         7271.0|            728.0| 1056.242424242424|\n",
            "|2000| ACRE|          430.0|             NULL|-5784.757575757576|\n",
            "|1999| ACRE|          347.0|             NULL|-5867.757575757576|\n",
            "|2002| ACRE|         7985.0|             NULL| 1770.242424242424|\n",
            "|2013| ACRE|         4980.0|            221.0|-1234.757575757576|\n",
            "|2003| ACRE|        10523.0|             NULL| 4308.242424242424|\n",
            "|2015| ACRE|         5779.0|            264.0| -435.757575757576|\n",
            "|2008| ACRE|         5699.0|            254.0| -515.757575757576|\n",
            "|2017| ACRE|         6295.0|            257.0| 80.24242424242402|\n",
            "|2009| ACRE|         3511.0|            167.0|-2703.757575757576|\n",
            "|2011| ACRE|         3191.0|            280.0|-3023.757575757576|\n",
            "|2019| ACRE|         6802.0|            688.0|  587.242424242424|\n",
            "+----+-----+---------------+-----------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Análise exploratória 1) - Evolução Anual das Queimadas por Estado\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "fires_by_year_state = fires_agg_df.groupBy(\"year\", \"state\").agg(\n",
        "    avg(\"avg_total_fires\").alias(\"avg_total_fires\")\n",
        ").orderBy(\"year\", \"state\")\n",
        "\n",
        "fires_by_year_state.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k35v2Zl9O7Rn",
        "outputId": "f189f47d-c8b6-424f-e845-4928bd4a6181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+---------------+\n",
            "|year|      state|avg_total_fires|\n",
            "+----+-----------+---------------+\n",
            "|1999|       ACRE|          347.0|\n",
            "|1999|      AMAPA|          101.0|\n",
            "|1999|   AMAZONAS|         1048.0|\n",
            "|1999|   MARANHAO|         4136.0|\n",
            "|1999|MATO GROSSO|        28538.0|\n",
            "|1999|       PARA|        20478.0|\n",
            "|1999|   RONDONIA|         7121.0|\n",
            "|1999|    RORAIMA|          220.0|\n",
            "|1999|  TOCANTINS|          869.0|\n",
            "|2000|       ACRE|          430.0|\n",
            "|2000|      AMAPA|          253.0|\n",
            "|2000|   AMAZONAS|          857.0|\n",
            "|2000|   MARANHAO|         4500.0|\n",
            "|2000|MATO GROSSO|        17242.0|\n",
            "|2000|       PARA|        18201.0|\n",
            "|2000|   RONDONIA|         5505.0|\n",
            "|2000|    RORAIMA|          362.0|\n",
            "|2000|  TOCANTINS|          818.0|\n",
            "|2001|       ACRE|          829.0|\n",
            "|2001|      AMAPA|         1300.0|\n",
            "+----+-----------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Análise exploratória 2) Estados com Maiores e Menores Anomalias de Queimadas\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "anomaly_by_state = fires_agg_df.groupBy(\"state\").agg(\n",
        "    avg(\"avg_fire_anomaly\").alias(\"avg_fire_anomaly\")\n",
        ").orderBy(\"avg_fire_anomaly\", ascending=False)\n",
        "\n",
        "anomaly_by_state.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkAE12pFTZLu",
        "outputId": "ffbdb3f0-625c-4940-ea28-ac296b8bb617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------------+\n",
            "|      state|   avg_fire_anomaly|\n",
            "+-----------+-------------------+\n",
            "|MATO GROSSO| 1669.8484848484852|\n",
            "|   MARANHAO|  263.5411255411259|\n",
            "|   RONDONIA| 248.30735930735906|\n",
            "|       PARA| 176.61904761904762|\n",
            "|    RORAIMA| 49.038961038961176|\n",
            "|      AMAPA|  41.46320346320334|\n",
            "|  TOCANTINS| 31.969696969696997|\n",
            "|       ACRE|-192.32900432900456|\n",
            "|   AMAZONAS| -383.5584415584416|\n",
            "+-----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Análise exploratória 3) Impacto dos fenômenos climáticos nas queimadas por estado ao longo do tempo\n",
        "from pyspark.sql.functions import avg, count, when\n",
        "\n",
        "# Filtrar dados com fenômeno não nulo\n",
        "df_phenomenon = fires_final.filter(fires_final.phenomenon.isNotNull())\n",
        "\n",
        "# Calcular média de queimadas por estado, ano e fenômeno\n",
        "fires_phenomenon_summary = df_phenomenon.groupBy(\"state\", \"year\", \"phenomenon\") \\\n",
        "    .agg(\n",
        "        avg(\"total_fires\").alias(\"avg_total_fires\"),\n",
        "    ) \\\n",
        "    .orderBy(\"state\", \"year\")\n",
        "\n",
        "fires_phenomenon_summary.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGrC-4dkUUfS",
        "outputId": "167f6bc6-92d1-4c7a-c962-625b8c73c9f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+---------------+\n",
            "|state|year|phenomenon|avg_total_fires|\n",
            "+-----+----+----------+---------------+\n",
            "| ACRE|1999|   La Nina|          347.0|\n",
            "| ACRE|2000|   La Nina|          430.0|\n",
            "| ACRE|2001|   La Nina|          829.0|\n",
            "| ACRE|2002|   El Nino|         7985.0|\n",
            "| ACRE|2003|   El Nino|        10523.0|\n",
            "| ACRE|2004|   El Nino|         7271.0|\n",
            "| ACRE|2005|   El Nino|        15993.0|\n",
            "| ACRE|2005|   La Nina|        15993.0|\n",
            "| ACRE|2006|   El Nino|         6198.0|\n",
            "| ACRE|2006|   La Nina|         6198.0|\n",
            "| ACRE|2007|   El Nino|         8549.0|\n",
            "| ACRE|2007|   La Nina|         8549.0|\n",
            "| ACRE|2008|   La Nina|         5699.0|\n",
            "| ACRE|2009|   La Nina|         3511.0|\n",
            "| ACRE|2009|   El Nino|         3511.0|\n",
            "| ACRE|2010|   La Nina|         8661.0|\n",
            "| ACRE|2010|   El Nino|         8661.0|\n",
            "| ACRE|2011|   La Nina|         3191.0|\n",
            "| ACRE|2012|   La Nina|         4720.0|\n",
            "| ACRE|2014|   El Nino|         4398.0|\n",
            "+-----+----+----------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Análise exploratória 4) correlação entre Severidade dos Fenômenos Climáticos e Nível de Queimadas\n",
        "from pyspark.sql.functions import count, collect_set\n",
        "\n",
        "df_severity_fire_level = fires_final.filter(\"severity IS NOT NULL\") \\\n",
        "    .groupBy(\"severity\", \"fire_level\").agg(\n",
        "    count(\"*\").alias(\"occurrences\")\n",
        ").orderBy(\"severity\", \"fire_level\")\n",
        "\n",
        "\n",
        "df_phenomenon_by_severity = fires_final.filter(\"severity IS NOT NULL\") \\\n",
        "    .groupBy(\"severity\") \\\n",
        "    .agg(collect_set(\"phenomenon\").alias(\"phenomena\"))\n",
        "\n",
        "df_phenomenon_by_severity.show(truncate=False)\n",
        "\n",
        "df_severity_fire_level.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WTwZQYrV0bU",
        "outputId": "52db750a-7faa-49fe-b99e-1d775c77dd0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|severity   |phenomena         |\n",
            "+-----------+------------------+\n",
            "|Strong     |[La Nina]         |\n",
            "|Very Strong|[El Nino]         |\n",
            "|Weak       |[El Nino, La Nina]|\n",
            "|Moderate   |[El Nino, La Nina]|\n",
            "+-----------+------------------+\n",
            "\n",
            "+-----------+----------+-----------+\n",
            "|   severity|fire_level|occurrences|\n",
            "+-----------+----------+-----------+\n",
            "|   Moderate|      High|         14|\n",
            "|   Moderate|       Low|         10|\n",
            "|   Moderate|    Medium|         30|\n",
            "|     Strong|      High|         13|\n",
            "|     Strong|       Low|         20|\n",
            "|     Strong|    Medium|         21|\n",
            "|Very Strong|      High|          5|\n",
            "|Very Strong|       Low|          2|\n",
            "|Very Strong|    Medium|         11|\n",
            "|       Weak|      High|         44|\n",
            "|       Weak|       Low|         39|\n",
            "|       Weak|    Medium|         79|\n",
            "+-----------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Análise exploratória 5) Detecção de Outliers na Média de Focos de Incêndio por Estado e Ano utilizando quartis\n",
        "from pyspark.sql.functions import col, percentile_approx\n",
        "\n",
        "# Coletar Q1 e Q3\n",
        "q1, q3 = fires_agg_df.approxQuantile(\"avg_total_fires\", [0.25, 0.75], 0.01)\n",
        "iqr = q3 - q1\n",
        "\n",
        "# Definir limites de outliers\n",
        "lower_bound = q1 - 1.5 * iqr\n",
        "upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "# Filtrar anos outliers\n",
        "df_outliers = fires_agg_df.filter(\n",
        "    (col(\"avg_total_fires\") < lower_bound) | (col(\"avg_total_fires\") > upper_bound)\n",
        ")\n",
        "\n",
        "df_outliers.select(\"year\", \"state\", \"avg_total_fires\", \"avg_fire_anomaly\") \\\n",
        "    .orderBy(\"avg_total_fires\", ascending=False) \\\n",
        "    .show(40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml-Q5PX4cpIv",
        "outputId": "bcacbe63-2ae3-4f46-eb2a-b0788bfd9697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+---------------+------------------+\n",
            "|year|      state|avg_total_fires|  avg_fire_anomaly|\n",
            "+----+-----------+---------------+------------------+\n",
            "|2002|       PARA|       106849.0|           62155.0|\n",
            "|2002|MATO GROSSO|        79680.0| 52998.51515151515|\n",
            "|2004|       PARA|        74214.0|           29520.0|\n",
            "|2005|       PARA|        71477.0|           26783.0|\n",
            "|2004|MATO GROSSO|        70422.0| 43740.51515151515|\n",
            "|2007|       PARA|        68491.0|           23797.0|\n",
            "|2010|       PARA|        57196.0|           12502.0|\n",
            "|2006|       PARA|        55840.0|           11146.0|\n",
            "|2005|MATO GROSSO|        53489.0|26807.515151515152|\n",
            "|2003|       PARA|        53040.0|            8346.0|\n",
            "|2007|MATO GROSSO|        52399.0|25717.515151515152|\n",
            "|2003|MATO GROSSO|        50713.0|24031.515151515152|\n",
            "|2017|       PARA|        49770.0|            5076.0|\n",
            "|2008|       PARA|        48449.0|            3755.0|\n",
            "|2015|       PARA|        43164.0|           -1530.0|\n",
            "|2009|       PARA|        41664.0|           -3030.0|\n",
            "|2005|   RONDONIA|        41641.0| 25674.21212121212|\n",
            "|2004|   RONDONIA|        40824.0| 24857.21212121212|\n",
            "|2002|   RONDONIA|        39132.0| 23165.21212121212|\n",
            "|2012|       PARA|        37221.0|           -7473.0|\n",
            "|2014|       PARA|        35526.0|           -9168.0|\n",
            "|2006|MATO GROSSO|        32745.0| 6063.515151515152|\n",
            "|2003|   RONDONIA|        30533.0|14566.212121212122|\n",
            "+----+-----------+---------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# salvando os dataframes que serão usados no loocker studio\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "fires_by_year_state.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\")\\\n",
        "    .csv(\"/content/drive/MyDrive/queimadas/fires_state_year\")\n",
        "\n",
        "anomaly_by_state.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\")\\\n",
        "    .csv(\"/content/drive/MyDrive/queimadas/fire_by_phenomenon\")\n",
        "\n",
        "fires_phenomenon_summary.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\")\\\n",
        "    .csv(\"/content/drive/MyDrive/queimadas/severity_phenomenon\")\n",
        "\n",
        "df_severity_fire_level.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\")\\\n",
        "    .csv(\"/content/drive/MyDrive/queimadas/severity_fire\")\n",
        "\n",
        "df_outliers.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\")\\\n",
        "    .csv(\"/content/drive/MyDrive/queimadas/df_outliers\")\n",
        "\n",
        "fires_final.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\")\\\n",
        "    .csv(\"/content/drive/MyDrive/queimadas/fires_final\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo8ObB_cPDnF",
        "outputId": "ab54c9c6-a9d6-45a0-dce6-38d769f78a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finalizando sessão com o spark\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "7SW3UWswHH7c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}